---
title: "localPCA Tutorial"
output:
  prettydoc::html_pretty:
    theme: cayman
fontsize: 18pt
---

# Background

## What is structural variation?

## Why is it interesting?

## Methods for detecting them

### Local PCA

Here is the paper describing the method: https://academic.oup.com/genetics/article/211/1/289/5931130?login=true

# The dataset

WGS of sea urchins

# Steps already completed

These are steps that are already done for you, you will not need to run any of this.

## Mapped reads to the reference

### The reference genome

<https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_000002235.5/>

21_scaffolds file in the `/netfiles/ecogen/structural_variation/`

### The mapping algorythm

Input: List of read files (R1 and R2)

```{bash}
while read line ; do
        F1=$(cut -d ' ' -f1 <<< $line)
        F2=$(cut -d ' ' -f2 <<< $line)
        echo "$F1 -- $F2"
        FILE=$(mktemp)
        cat header.txt >> $FILE
        echo "spack load samtools@1.10" >> $FILE
        echo "spack load bwa@0.7.17" >> $FILE
        ref="/users/c/p/cpetak/WGS/reference_genome/GCF_000002235.5_Spur_5.0_genomic.fna"
        out_name=$(cut -d '.' -f1 <<< $F1)
        echo "bwa mem -t 1 -M $ref /users/c/p/cpetak/WGS/all_fastqs/$F1 /users/c/p/cpetak/WGS/all_fastqs/$F2 | samtools view -S -b > /users/c/p/cpetak/WGS/BWA_out/$out_name.bam" >> $FILE
        sbatch $FILE
        sleep 0.5
        rm $FILE
done < $1
```

The Burrows-Wheeler Alignment Tool (BWA) MEM algorithm was used for mapping the raw reads to the S. purpuratus reference genome (Spur ver. 5.0, scaffold N50 ∼37 Mbp). The average coverage for each individual was 6.42±0.78, with an average mapping rate of 81.6±0.01.

## Called variants for each chromosome across all individuals

Input:

-   21_scaffolds

-   list_of_files.txt, 140 lines, line 1: `/users/c/p/cpetak/WGS/BWA_out/BOD_18170X61_200925_A00421_0244_AHKML5DSXY_S81_L002_R1_001.rmdup.bam`

```{bash}
while read line ; do
	echo "$line"
	FILE=$(mktemp)
  cat header.txt >> $FILE
  ref="/users/c/p/cpetak/WGS/reference_genome/GCF_000002235.5_Spur_5.0_genomic.fna"
  echo "echo "${line}" " >> $FILE
  echo "bcftools mpileup -r $line -f $ref --bam-list list_of_files.txt | bcftools call -mv -Ob -o multi_bam_${line}.bcf" >> $FILE
  sbatch $FILE
  sleep 0.5
  rm $FILE
done < $1
```

Output: bcf files in the `/netfiles/ecogen/structural_variation/bcf_files directory`

# Filtering the bcf files

Before we do anything else, let's filter these bcf files. In order to look at them we will convert them into a vcf format shortly.

## List of chromosomes to choose from:

TODO: select best 16 chromosomes

## Write a bash script to do the filtering for your chromosome

-   cd into your myscripts directory, `cd ~/myscripts`

-   type `vim filter_chromosome.sh`, then hit the "i" key to enter insert mode

-   copy the following lines:

```{bash}
#!/bin/sh

mychr="my_chromosome_number" # Replace this with your chromosome

# use bcftools to filter your chromosome. The output of this line will be a vcf file that we can look at
# NOTE: Everyone will be writing to the same shared directory, so please make sure that you have the correct chromosome name above

bcftools view -e 'QUAL <= 40 || DP < 560 || MQB < -3 || RPB < -3 || RPB > 3 || AN < 238' /netfiles/ecogen/structural_variation/bcf_files/multi_bam_${mychr}.bcf > /netfiles/ecogen/structural_variation/filtered_bcf_files/${mychr}_filtered.vcf

echo "Filtered bcf" # Some printing to keep track of progress

# Convert the filtered vcf into the bcf file type which is the type the R package will be expecting

bcftools view -Ob /netfiles/ecogen/structural_variation/filtered_bcf_files/${mychr}_filtered.vcf > /netfiles/ecogen/structural_variation/filtered_bcf_files/${mychr}_filtered.bcf

echo "Converted to bcf" # Some printing to keep track of progress

# Index the filtered bcf file. This will make the file more searchable by the algorythm reading it.

bcftools index /netfiles/ecogen/structural_variation/filtered_bcf_files/${mychr}_filtered.bcf
echo "Indexed bcf"
echo "Done!"
```

## A bit on tmux

Before running the script above in tmux, I wanted to go over how to use tmux in a few minutes.

Tmux is a great package that allows you to switch easily between several programs in one terminal, detach them (they keep running in the background) and reattach them when you want to look at it again.

When you type tmux and hit enter, you create a new session that you can detach from using `Ctrl B + D`. However, if you type tmux again in the future, you will again create a new session instead of opening the previous one. If you do this repeatedly, you will end up creating a lot of sessions in the background at the same time. In order to be able to navigate back to a specific session later, you should instead type:

`tmux new -s mysession` where mysession is the name of your session. So, for example now you can type:

`tmux new -s bcf_filtering`. Then you can list the sessions you are currently running with

`tmux ls`. If you see a lot of sessions being printed to the screen and you want to get rid of them all, type

`tmux kill-session`. Great! Now that your tmux is all clean, let's create a new session again named bcf_filtering:

`tmux new -s bcf_filtering`. Hit Enter. Type `Ctrl B + D`. Since we named it, you can open the same session again:

`tmux attach-session -t bcf_filtering`. Yay! Now run the filtering script by typing `bash filter_chromosome.sh`. The code should complete in 6 minutes. Hit `Ctrl B + D` to detach the session. If you want to look at the progress, you can type `tmux attach-session -t bcf_filtering` again!

## The vcf file format

While the filtering is running, let's look at the vcf file that we are creating in the process. I have an example for you ready in `/netfiles/ecogen/structural_variation/examples`. Go ahead and cd into it. DO NOT try to open the vcf file with vim, it WILL crush your computer :). Instead, type `head NW_022145602.1_filtered.vcf` to print the first 10 lines.

VCF, variant call format, is an extremely common, standardized file format to store genetic information in. It always starts with a few (or many in our case) header lines that start with `##`. These header lines contain information about how the vcf file was generated, followed by information about the reference. Go ahead and type `more NW_022145602.1_filtered.vcf` and hit Enter. The more command is similar to the head command, but it allows you to move down in the file by hitting Enter. You will see that we have a lot of scaffolds listed in this file, so instead of hitting and infinite amount of Enters, hit `Ctrl C` to exit the more command, and then type `more -900 NW_022145602.1_filtered.vcf` to jump to line 900. After all the scaffold information, you will see a description of what the different sections in the INFO column in the vcf file mean. I decided to filter on:

-   DP, which is Raw read depth, across all individuals (so 560 reads is 4 depth on average among 140 individuals)

-   MQB, Mann-Whitney U test of Mapping Quality Bias, "If p \< 0.05, it suggests there is significant bias i.e. the reads supporting alternate allele have lower mapping quality than reads supporting reference allele. The bigger p value is better."

-   RPB, Mann-Whitney U test of Read Position Bias, "alleles present at the end of reads may not be right".

-   AN, Total number of alleles in called genotypes, we have a total of 2 (heterozygote) x 140 (number of individuals) alleles. 85% is my cut off.

I decided on these values based on similar literature I found, and also the percent data loss after applying different levels of filtering.

Now let's look further down in the file. You should see a header line that lists the column names:

`#CHROM    POS ID  REF ALT QUAL    FILTER  INFO    FORMAT` followed by a 140 long names. This is a standard format. Keep pressing enter until you find the first line. - CHROM is the chromosome name

-   POS is the position in the chromosome

-   ID can be an ID assigned to the specific variant. In some model organisms, like humans, there are known named variants. That information would go here. If you are curious, you can browse those here: <https://www.ncbi.nlm.nih.gov/variation/view/>

-   REF allele in the reference

-   ALT allele in your dataset

-   QUAL posterior genotype probability in Phred scale. QUAL = 20 means there is 99% probability that there is a variant at the site. I decided to filter out sites with QUAL \<= 40.

-   FILTER If all filters are passed, PASS is written in the filter column. These are default filters during the variant calling, takes depth of coverage, genotyping quality and variant quality into account.

-   INFO Some information about the variant, see description in the vcf file header lines I mentioned above.

-   FORMAT Specifies the format in which the genotype data is given. In this case, it is GT:PL. GT - Genotype, PL - List of Phred-scaled genotype likelihoods.

Let's look at an example!

Example 1:

```{bash}
NW_022145602.1	1564	.	T	A	129	.	DP=599;VDB=0.259328;SGB=31.2596;RPB=0.70951;MQB=0.816143;MQSB=0.0194;BQB=0.892443;MQ0F=0.358932;ICB=0.000506821;HOB=0.000246914;AC=3;AN=270;DP4=385,98,11,1;MQ=21	GT:PL	./.:0,0,0	0/0:0,12,76	0/0:0,6,74	0/0:0,15,118	0/0:0,3,4	0/1:31,0,28	0/0:0,9,40	0/0:0,6,7 0/0:0,6,42	0/0:0,12,11	0/0:0,3,4	0/0:0,3,37	0/0:0,21,171	0/0:0,3,4	./.:0,0,0	0/0:0,15,69	0/0:0,15,41	0/0:0,24,99	0/0:0,6,67	0/
0:0,12,77	0/0:0,15,120	0/0:0,15,117	0/0:0,3,37	0/0:0,9,42	0/0:0,9,13	0/0:0,21,98	0/0:0,9,9	0/0:0,3,37	0/0:0,3,40	0/0:0,15,69	0/
0:0,15,16	0/0:0,12,43	0/0:0,3,4	0/0:0,9,75	0/0:0,18,119	0/0:0,6,36	0/0:0,6,39	0/0:0,3,37	0/0:0,15,98	0/0:0,6,39	./.:0,0,0	0/
0:0,9,77	0/0:0,9,74	0/0:0,12,60	0/0:0,3,4	0/0:0,6,39	0/0:0,12,44	0/0:0,9,68	0/0:0,15,103	0/0:0,9,71	0/0:0,18,122	0/0:0,9,40	0/
0:0,12,59	0/0:0,18,102	0/0:0,6,64	0/0:0,15,71	0/0:0,12,99	0/0:0,6,74	0/0:0,3,37	0/0:0,24,128	0/0:0,18,108	0/1:122,0,34 (...)
```

0/0: homozygote to the alternative allele 0/1: heterozygote. since we don't know which allele is coming from which parent, 0/1 just means heterozygote, and you won't see 1/0 anywhere. 1/1: homozygote for the alternative allele

The likelihood scores: "Scores for 0/0 (homozygous ref), 0/1 (heterozygous), and 1/1 (homozygous alt) genotypes. For a phred-scaled likelihood of P, the raw likelihood of that genotype L = 10\^(-P/10) (so the higher the number, the less likely it is that your sample is that genotype). The sum of likelihoods is not necessarily 1."

NOTE: in module 1, population genetics on red spruce data, we were looking at SNP information at biallelic sites. As you can see if you scroll down, this dataset also includes sites with duplications/deletions/insertions, as well as triallelic (or even quadrallelic) sites.

Example 2:

```{bash}
NW_022145602.1	1553	.	ag	a,aGg	999	.	INDEL;IDV=7;IMF=0.7;DP=583;VDB=0.0245597;SGB=-53.7492;MQSB=0.0144647;MQ0F=
0.447684;ICB=0.473584;HOB=0.0514945;AC=79,2;AN=274;DP4=286,108,161,28;MQ=20	GT:PL	0/0:0,3,4,3,4,4	0/0:0,5,57,9,60,57	0/0:0,9,42
,9,42,42	0/1:26,0,1,44,10,35	0/0:0,3,4,3,4,4	0/0:0,12,69,12,69,69	0/1:25,5,0,28,9,25	0/1:7,5,0,10,9,7	1/1:39,6,0
,39,6,39	0/0:0,15,12,15,12,12 (...) 1/1:21,8,0,24,12,21	0/0:0,18,33,12,36,33	0/0:0,6,34
,6,34,34	0/1:6,0,69,15,72,81	0/1:3,0,25,18,31,35	0/1:55,5,0,61,12,56	0/0:0,9,87,9,87,87	0/0:0,15,60,15,60,60	0/
0:0,3,3,6,6,4	0/0:0,3,4,3,4,4	1/1:48,9,0,57,21,49	0/1:16,0,3,22,9,24	1/1:52,6,0,52,6,52	0/0:0,21,81,21,81,81	0/1:0,0,16
,6,25,21	0/0:0,9,61,9,61,61	0/1:27,0,42,36,51,74	0/1:44,0,26,59,32,77	0/1:14,0,30,23,33,50	0/1:20,3,0,20,3,20	1/
1:72,12,0,72,12,72	0/1:23,3,0,29,9,25	0/0:0,12,13,12,13,13	0/1:26,5,0,29,9,26	0/0:0,9,21,9,21,21	0/1:3,3,0,6,6,4	0/
0:0,15,65,15,65,65	0/0:0,5,58,9,61,58	0/0:0,9,15,9,15,15	0/0:0,3,4,3,4,4	0/1:48,0,16,54,28,70	0/0:0,1,22,3,25,24	0/
1:11,2,0,17,6,14	1/2:89,62,59,30,0,22	0/1:50,3,0,53,6,51	0/0:0,6,8,6,8,8	0/0:0,3,31,3,31,31	0/0:0,9,37,9,37,37	0/
0:0,15,109,15,109,109	0/1:17,0,78,35,81,108	0/0:0,2,78,12,81,85	0/1:47,0,56,59,69,110	1/1:68,6,0,68,6,68	0/0:0,9,55,9,55,55
	0/0:0,9,65,9,65,65	0/1:2,0,1,14,4,12	0/0:0,9,71,9,71,71	1/1:99,18,0,99,18,99	0/2:62,71,94,0,36,27 (...)
```

In this case, the reference is has AG, the first alternative has a deletion of the G, and the second allele has an addition of a G! So for example, 0/2 is a heterozygote where one copy has the insertion, and 1/1 is a homozygote for the deletion.

# Running local PCA

Local PCA is an R package, here is the GitHub page: https://github.com/petrelharp/local_pca. I already install this package on the class server following the instructions in the README.md. You should be able to use it without doing anything.

On the page, they also have an Rscript to use the package and a separate one to visualise the results, which I copied to the server (and slightly modified): `/netfiles/ecogen/structural_variation`.

show run_lostruct.R and summarize_run.Rmd on github, and on the server

mkdir struct_data directory in \~/mydata cp /netfiles/ecogen/structural_variation/filtered_bcf_files/NW_022145602.1_filtered.bcf\* \~/mydata/struct_data Could take a moment Now struct_data should have NW_022145602.1_filtered.bcf and NW_022145602.1_filtered.bcf.csi cp /netfiles/ecogen/structural_variation/run_lostruct.R \~/myscripts cp /netfiles/ecogen/structural_variation/summarize_run.Rmd \~/myscripts

tmux new -s run_localPCA cd \~/mydata/struct_data Rscript \~/myscripts/run_lostruct.R -i \~/mydata/struct_data -t snp -s 1000 -I /netfiles/ecogen/structural_variation/sample_info.tsv should take 15 mins Now you should have a folder called lostruct_results cd into lostruct_results cd into type_snp_size_1000_weights_none_jobid_166584 - will be called different for you Output files: config.json -\> check with vim mds_coords.csv -\> wc -l NW_022145602.1.pca.csv -\> wc -l and awk -F',' '{print NF}' NW_022145599.1.pca.csv \| sort -nu \| tail -n 1 -\> 283 For each window (rows), PC1 and PC2 for each individuals (140) -\> input variables for the MDS NW_022145602.1.regions.csv -\> windows information (will be important later)

## Check and visualise results

Rscript -e 'templater::render_template("~/myscripts/summarize_run.Rmd",output="~/mydata/struct_data/lostruct_results/type_snp_size_1000_weights_none_jobid_166584/run_summary.html",change.rootdir=TRUE)'

Get the run_summary.html through the FileZilla Open in your browser Look through figure

## Select regions of interest

Select a corner you are interested in Let's say corner 1 (local region and good PCA separation) corner.regions variable in summarize_run.Rmd has a list of regions for each corner, chrom, start, end 1st corner: corner.regions[[1]]$start 2nd corner: corner.regions[[2]]$start to save coordinates add the following line in the summarize_run.Rmd file write.csv(corner.regions[[2]], "second_corner.csv", row.names=FALSE) run again the summarize_run.Rmd script

## Do GO Enrichment

sed to modify second_corner

show how i got the annotation file (ncbi)

cd \~/mydata/struct_data/lostruct_results/type_snp_size_1000_weights_none_jobid_166584

/netfiles/ecogen/structural_variation/bedtools2/bin/intersectBed -a second_corner_formatted.csv -b /netfiles/ecogen/structural_variation/genome_annotation.gff -wa -wb \> genes_in_regions.bed

sed -n "s/\^.*gene=*$LOC[0-9]\+$.\$/\\1/p" genes_in_regions.bed \> gene_names.txt sort gene_names.txt \| uniq \> uni_gene_names.txt

copy to <https://geneontology.org/>
