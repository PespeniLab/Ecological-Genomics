---
title: "P/BIO381 Tutorials: Working with RNA-seq data"
subtitle: "RNAseq Day 2"
date: 'October 4, 2021'
output:
  prettydoc::html_pretty:
    theme: cayman
fontsize: 18pt
---

# Learning Objectives for today

1. Refresh on activities from the last coding session (experimental design, hypotheses, RNAseq pipeline, ran FastQC to check quality).
2. Check Run FastQC on raw and cleaned reads.
3. Start to map reads (to an existing reference transcriptome) and quantify abundance simultaneously using [Salmon](https://www.nature.com/articles/nmeth.4197).
4. Import quant.sf files generated by Salmon into [DESeq2](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html) for analysis and visualization.


## 1. Acartia hudsonica experimental evolution RNAseq experiment
  
### Realized sample replication after sequencing:  N=38 x 2 = 76 (left and right reads)

|Trt        | Generation  |Nreps  |
|-----------|-------------|-------|
|Ambient (AA)    |F0      |3      |
|Ambient (AA)    |F2      |2      |
|Ambient (AA)    |F4      |3      |
|Ambient (AA)    |F11     |3      |
|Acidification (AH)    |F0       |3      |
|Acidification (AH)    |F2       |3      |
|Acidification (AH)    |F4      |3      |
|Warming (HA)       |F0      |3      |
|Warming (HA)       |F2      |3      |
|Warming (HA)       |F4      |3      |
|Acidification+Warming (HH)    |F0      |3     |
|Acidification+Warming (HH)    |F4      |3    |
|Acidification+Warming (HH)    |F11     |3    |
|-----------|-------------|-------|
|Total      |             |38     |

In `/data/project_data/RNAseq/rawdata/`, there should be 76 files: N=38 x 2 = 76 (left and right reads, `_1.fq.gz`, `_2.fq.gz`)


## Questions can we ask with this experimental design and these data
1. Additive impact of acidification and warming? Do these result in similar changes in gene expression?
2. How does gene expression change across generations? How much of this is heritable? Could only do this across all 4 at F4 generation
3. How does gene expression change across time? Basically a time course to see if allele frequency and/or gene expression are headed in the same direction.
4. What is the rate at which the alleles become fixed?
5. How does expression of specific gene classes change across time? This would be cool with multiple graphs for each gene class
6. Plasticity in response for each treatment. We can compare the treatments to the ambient to figure this out and see if changes are maintained across generations.
7. Check completeness of the transcriptome based on a set of housekeeping/core genes for eukaryotes. Isn't taxa specific.


## 2. Compare quality using FastQC of raw and cleaned (Trimmomatic) reads
 
### FastQC
To visualize the quality more systematically for all reads in the file, we can use [the program FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/).

FastQC will accept multiple file names as input, so figure out which letters in the filename plus a wildcard (*) will capture just the files of your group of samples.

**From last time:**
```
cd /data/project_data/RNAseq/rawdata
fastqc FILENAME*.fq.gz --outdir=/data/project_data/RNAseq/fastqc/
```

One of us can also run `multiqc` to make one summary file for all of our .html fastQC files (really handy instead of flipping through 76 files!).
Navigate to the directory with our fastqc .html files and simply run `multiqc .`, which means use all the `.html` files in this `.` directory!

Now move the .html files to your local machine using your favorite file transfer method (WinSCP, Fetch, scp, etc.). Open the html files by double clicking and you should see your FastQC and multiqc reports! (one fastqc for each file and one multiqc for the whole dataset)


### Clean the reads with Trimmomatic (ALREADY DONE THIS TIME)

[Here's a link to the Trimmomatic program](http://www.usadellab.org/cms/index.php?page=trimmomatic) that we'll use to clean the reads for each file. The program is already installed in our `/data/popgen/` directory.

Already done, but for your reference, let's walk through the script:

```trim_loop.sh
#!/bin/bash   
 
# Below is a script to loop through the files in the /rawdata directory, identify matches,  
# and clean the fastq files, and direct output to /cleandata 
 
cd /data/project_data/RNAseq/rawdata
 
for f1 in *_1.fq.gz  
 
do 

 f2=${f1%%_1.fq.gz}"_2.fq.gz"  
 
java -classpath /data/popgen/Trimmomatic-0.39/trimmomatic-0.39.jar org.usadellab.trimmomatic.TrimmomaticPE \
        -threads 10 \
        -phred33 \
         "$f1" \
         "$f2" \
         /data/project_data/RNAseq/cleandata/"$f1"_left_clean_paired.fq \
         /data/project_data/RNAseq/cleandata/"$f1"_left_clean_unpaired.fq \
         /data/project_data/RNAseq/cleandata/"$f2"_right_clean_paired.fq \
         /data/project_data/RNAseq/cleandata/"$f2"_right_clean_unpaired.fq \
        ILLUMINACLIP:/data/popgen/Trimmomatic-0.39/adapters/TruSeq3-PE.fa:2:30:10 \
        LEADING:20 \
        TRAILING:20 \
        SLIDINGWINDOW:6:20 \
        MINLEN:36 
>> log.txt
 
done 
```
### Run FastQC on the clean reads to confirm improvement

  * What do we look for in this second run?
  * [MULTIQC](https://multiqc.info/docs/) is a tool to generate a single summary html report file from all the fastqc reports generated.
  
Recall, use the letters in the filename plus a wildcard (*) that will capture just the files of your group of samples (use the same group of files as last time).
```
cd /data/project_data/RNAseq/cleandata
fastqc FILENAME*.fq.gz --outdir=/data/project_data/RNAseq/fastqc/clean
```

Again, someone can run `multiqc .` once all of the fastqc files have been generated.

We can move these (or just the multiqc.html) file/s to our local machines to see the .html output summary on the quality of our cleaned data.

## 3. Use Salmon to quantify transcript abundance

1. First step: Index the reference transcriptome.
This only needs to be done once and has been done already, but here's the code:
```
cd /data/project_data/RNAseq/assembly/
conda activate salmon

salmon index -t Bridger.fasta -i hudsonica_index -p 8
```
`-p` says how many threads to use 

2. Second step: Start quantification!
Below is the basic command for running the quantification from the documentation, [Salmon tutorial](https://salmon.readthedocs.io/en/latest/salmon.html)
```
screen
conda activate salmon
```

```
#!/bin/bash
######
#
# quantify each sample with salmon
#
#######

# -i points to the index files already created
# -l A tells salmon that it should automatically determine the library type of the sequencing reads (e.g. stranded vs. unstranded etc.)
# -p 8 says uses 8 threads
# -o indicates the directory and name of output
# seqbias corrects for random hexamer priming
# gcbias corrects for gcbias, but only when present.

conda activate salmon

for i in $(ls /data/project_data/RNAseq/cleandata | grep '.fq.gz' | cut -f 1-3 -d "_"| uniq);
do

    echo "starting sample ${i}"
    #starting with only name of rep. need to pull out files

    read1=$(ls /data/project_data/RNAseq/cleandata | grep ${i} | grep '_1.qc.fq.gz')
    read2=$(ls /data/project_data/RNAseq/cleandata | grep ${i} | grep '_2.qc.fq.gz')

    salmon quant -i /data/project_data/RNAseq/assembly/hudsonica_index \
        -l A \
         -1 /data/project_data/RNAseq/cleandata/${read1} \
         -2 /data/project_data/RNAseq/cleandata/${read2} \
         -p 8  \
         --softclip \
         --seqBias \
         --gcBias \
         -o /data/project_data/RNAseq/salmon/transcripts_quant/${i}

    echo "sample ${i} done"

done
```


The descriptions of all of the options can be found on the [Salmon github page](https://salmon.readthedocs.io/en/latest/salmon.html#description-of-important-options) and by using the command `salmon quant -h`.

## Explore mapping rate
For each sample mapped, you now have a directory with several output files including a log of the run. In that log, the mapping rate (% of reads mapped with sufficient quality) is reported. We can view the contents of the file using `cat`. 
We can also use `grep` (i.e., regular expressions) to pull out the mapping rate for all the samples. Though there's probably a more elegant solution, here is one:
```
grep -r --include \*.log -e 'Mapping rate'
```
* How could we save this output?
* What is our mapping rate? Is this good/enough? What factors could affect mapping rate?

## Combine individual `quant.sf` files from their respective directories into a counts data matrix with all 38 samples in one table
To do this, we'll use the R package `tximport` on our class server. 
Here's a `tximport` [tutorial](https://bioconductor.org/packages/release/bioc/vignettes/tximport/inst/doc/tximport.html#salmon) by the creators of the two programs, Salmon and DESeq2. 
Unless we decide to use multiple rounds of mapping (changing references, etc), only one person needs to make this compiled matrix.
Here's an example of how it can be done. First start `R` on the server by typing capital `R` and enter. Exciting! Right? Load the libraries we need (already installed).
```
library(tximportData)
library(tximport)

#locate the directory containing the files. 
dir <- "/data/project_data/RNASeq/salmon/"
list.files(dir)

# read in table with sample ids
samples <- read.table("/data/project_data/RNASeq/salmon/hudsonica_samples.txt", header=TRUE)

# now point to quant files
all_files <- file.path(dir, samples$sample, "quant.sf")
names(all_files) <- samples$sample

# what would be used if linked transcripts to genes
#txi <- tximport(files, type = "salmon", tx2gene = tx2gene)
# to be able to run without tx2gene
txi <- tximport(all_files, type = "salmon", txOut=TRUE)  
names(txi)

head(txi$counts)

countsMatrix <- txi$counts
dim(countsMatrix)
# should be about 51,000 by 38

# To write out
write.table(countsMatrix, file = "AH_countsMatrix.txt", col.names = T, row.names = T, quote = F) 
```
Now we can move this counts data matrix to your individual machines using your perferred ftp (fetch, Winscp, scp). Also move the `hudsonica_samples.txt` file to your machine. This file is a table that associates each of our samples with their conditions (treatment, generation, replicate).

## Import Counts Matrix and Sample ID tables into R and DESeq2 on your local machine!

Now we will work in R on our individual machines, each of us working with the complete data set (n=38, not just a subset of samples).

To get set up for next time:
```R

## Import or install the libraries that we're likely to need
library(DESeq2)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggpubr)
library(wesanderson)
library(vsn)  ### First: BiocManager::install("vsn") AND BiocManager::install("hexbin")
```
`Tools` -> `Install packages` -> Search for the library of interest; Install including dependencies.