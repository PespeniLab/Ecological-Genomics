# Title  

## Author: Lauren Ashlock  
### Affiliation:  UVM
### E-mail contact: Lauren.Ashlock@uvm.edu


### Start Date: 2020-01-13
### End Date: 2020-05-08
### Project Descriptions:   Class notes for ecological genomics





# Table of Contents:   
* [Entry 1: 2020-01-13, Monday](#id-section1) First day of class
* [Entry 2: 2020-01-14, Tuesday](#id-section2)
* [Entry 3: 2020-01-15, Wednesday](#id-section3) Second day of class Methods info update blitz and computer set-up
* [Entry 4: 2020-01-16, Thursday](#id-section4)
* [Entry 5: 2020-01-17, Friday](#id-section5)
* [Entry 6: 2020-01-20, Monday](#id-section6)
* [Entry 7: 2020-01-21, Tuesday](#id-section7)
* [Entry 8: 2020-01-22, Wednesday](#id-section8) Additional sequencing info updates
* [Entry 9: 2020-01-23, Thursday](#id-section9)
* [Entry 10: 2020-01-24, Friday](#id-section10)
* [Entry 11: 2020-01-27, Monday](#id-section11) Population genomics and paper discussion
* [Entry 12: 2020-01-28, Tuesday](#id-section12)
* [Entry 13: 2020-01-29, Wednesday](#id-section13) PopGen Coding Day One
* [Entry 14: 2020-01-30, Thursday](#id-section14)
* [Entry 15: 2020-01-31, Friday](#id-section15)
* [Entry 16: 2020-02-03, Monday](#id-section16) Paper discussion
* [Entry 17: 2020-02-04, Tuesday](#id-section17)
* [Entry 18: 2020-02-05, Wednesday](#id-section18) Pop Gen Tutorial Day Two
* [Entry 19: 2020-02-06, Thursday](#id-section19)
* [Entry 20: 2020-02-07, Friday](#id-section20)
* [Entry 21: 2020-02-10, Monday](#id-section21)
* [Entry 22: 2020-02-11, Tuesday](#id-section22)
* [Entry 23: 2020-02-12, Wednesday](#id-section23) Out sick - looking through tutorial at home
* [Entry 24: 2020-02-13, Thursday](#id-section24)
* [Entry 25: 2020-02-14, Friday](#id-section25)
* [Entry 26: 2020-02-17, Monday](#id-section26)
* [Entry 27: 2020-02-18, Tuesday](#id-section27)
* [Entry 28: 2020-02-19, Wednesday](#id-section28) Pop Gen Day Four
* [Entry 29: 2020-02-20, Thursday](#id-section29)
* [Entry 30: 2020-02-21, Friday](#id-section30)
* [Entry 31: 2020-02-24, Monday](#id-section31) Transcriptomics Day One
* [Entry 32: 2020-02-25, Tuesday](#id-section32)
* [Entry 33: 2020-02-26, Wednesday](#id-section33) Transcriptomics first coding session
* [Entry 34: 2020-02-27, Thursday](#id-section34)
* [Entry 35: 2020-02-28, Friday](#id-section35)
* [Entry 36: 2020-03-02, Monday](#id-section36) DGE info update Sea cucumbers and hydrostatic pressure
* [Entry 37: 2020-03-03, Tuesday](#id-section37)
* [Entry 38: 2020-03-04, Wednesday](#id-section38) Transcriptomics Day Two Mapping with Salmon and then differential expression in R
* [Entry 39: 2020-03-05, Thursday](#id-section39)
* [Entry 40: 2020-03-06, Friday](#id-section40)
* [Entry 41: 2020-03-09, Monday](#id-section41)
* [Entry 42: 2020-03-10, Tuesday](#id-section42)
* [Entry 43: 2020-03-11, Wednesday](#id-section43)
* [Entry 44: 2020-03-12, Thursday](#id-section44)
* [Entry 45: 2020-03-13, Friday](#id-section45)
* [Entry 46: 2020-03-16, Monday](#id-section46)
* [Entry 47: 2020-03-17, Tuesday](#id-section47)
* [Entry 48: 2020-03-18, Wednesday](#id-section48) First day of remote classes transcriptomics day 3
* [Entry 49: 2020-03-19, Thursday](#id-section49)
* [Entry 50: 2020-03-20, Friday](#id-section50)
* [Entry 51: 2020-03-23, Monday](#id-section51)
* [Entry 52: 2020-03-24, Tuesday](#id-section52)
* [Entry 53: 2020-03-25, Wednesday](#id-section53)
* [Entry 54: 2020-03-26, Thursday](#id-section54)
* [Entry 55: 2020-03-27, Friday](#id-section55)
* [Entry 56: 2020-03-30, Monday](#id-section56)
* [Entry 57: 2020-03-31, Tuesday](#id-section57)
* [Entry 58: 2020-04-01, Wednesday](#id-section58)
* [Entry 59: 2020-04-02, Thursday](#id-section59)
* [Entry 60: 2020-04-03, Friday](#id-section60)
* [Entry 61: 2020-04-06, Monday](#id-section61)
* [Entry 62: 2020-04-07, Tuesday](#id-section62)
* [Entry 63: 2020-04-08, Wednesday](#id-section63)
* [Entry 64: 2020-04-09, Thursday](#id-section64)
* [Entry 65: 2020-04-10, Friday](#id-section65)
* [Entry 66: 2020-04-13, Monday](#id-section66)
* [Entry 67: 2020-04-14, Tuesday](#id-section67)
* [Entry 68: 2020-04-15, Wednesday](#id-section68)
* [Entry 69: 2020-04-16, Thursday](#id-section69)
* [Entry 70: 2020-04-17, Friday](#id-section70)
* [Entry 71: 2020-04-20, Monday](#id-section71)
* [Entry 72: 2020-04-21, Tuesday](#id-section72)
* [Entry 73: 2020-04-22, Wednesday](#id-section73)
* [Entry 74: 2020-04-23, Thursday](#id-section74)
* [Entry 75: 2020-04-24, Friday](#id-section75)
* [Entry 76: 2020-04-27, Monday](#id-section76)
* [Entry 77: 2020-04-28, Tuesday](#id-section77)
* [Entry 78: 2020-04-29, Wednesday](#id-section78)
* [Entry 79: 2020-04-30, Thursday](#id-section79)
* [Entry 80: 2020-05-01, Friday](#id-section80)
* [Entry 81: 2020-05-04, Monday](#id-section81)
* [Entry 82: 2020-05-05, Tuesday](#id-section82)
* [Entry 83: 2020-05-06, Wednesday](#id-section83)
* [Entry 84: 2020-05-07, Thursday](#id-section84)
* [Entry 85: 2020-05-08, Friday](#id-section85)

------
<div id='id-section1'/>   

### Entry 1: 2020-01-13, Monday.   

#### Introductions

#### What is ecological genomics?

- Species interactions at the genomic level
- Study of genes and relation to organisms in their environment
- In the context of evolution

#### Overlapping of fields

**Popgen**: 1920/30s Wright, Fisher, Haldane 
- Mathematical theory: based on a theoretical unchanging population
- Fst population level differentiation
- Selection: thinking in terms of the relative fitness of different genotypes

**Molecular evolution**: Kimura Tajima
- How does the DNA reveal the history of an organism/population/species
- Can look at pos/neg selection by comparing nonsynonymous to synonymous changes in the DNA
- Can look at the nucleotide diversity, processes of evolution can influence diversity stats

Merge these two fields with ecology and NGS -> ecological genomics 

#### Class structure
Mondays: mini lectures/info updates and journal review
Wednesdays: Computer lab 

------
<div id='id-section2'/>   

### Entry 2: 2020-01-14, Tuesday.   



------
<div id='id-section3'/>   

### Entry 3: 2020-01-15, Wednesday.   

#### How to pick a platform/method

- Question
- Organisms / sample (tissue type, environmental)
  - Is there a reference genome? 
  - Ploidy
  - DNA/RNA/? 
- Different library prep methods
  - Whole genome sequencing
  - RNAseq
  - Exome capture
  - GBS/Rad
  - Amplicon
  - Bisulfite/ATAC
- Sequencing platforms
  - Illumina
  - Pacbio/nanopore

#### Info updates

##### Chege: Illumina

[Video on Illumina platform](https://www.youtube.com/watch?v=fCd6B5HRaZ8#action=share)

1. Library prep
   1. Cut up DNA/RNA into pieces and attach adapters
2. Cluster generation
   1. Bind fragments of DNA to lawn of complementary sequences to adapters
   2. Through PCR process our fragments are magnified, to facilitate sequencing 
3. Sequencing by synthesis
   1. Add fluorescent dNTPs 
   2. As each base is read an image is stored
4. Data analysis

Why do we use this method?

- MiSeq: 30mill bp /run
- HiSeq: 3 bill /run
- NovaSeq: 13 bill / run
- Sanger: 400 /run 

##### Csenge: PacBio/Nanopore

- Two different approaches: SMRT or Synthetic
- PacBio and Nanopore both use SMRT method
  - PacBio
    - Utilize special flow cell with a bunch of small wells
    - Polymerase is fixed at the bottom of the well and the DNA passes across the wells
    - Fluorescence is recorded as each nucleotide is incorporated
  - Nanopore
    - directly detects sequence of DNA
    - Sequence moves through a pore and instead of looking at fluorescence of each base ... has unique sequence signal
- These methods are less accurate than short read sequencing and more expensive
- Can help with repetitive regions of DNA, get rid of potential gaps, helpful to identify alternative splicing



##### Erika: RNAseq

- Whole transcriptome shotgun sequencing
- Uses high throughput NGS technology to characterize gene expression patterns and to identify novel transcripts/molecular markers of interest
  - Can incorporate into your experimental framework
- Advantage: gives functionally relevant information about what is being expressed at that time point. Can also allow you to detect differences among populations (both gene expression and SNP differences).
- Limitations: some inherent error, RNA is a less stable molecule can introduce error/bias 
  - Need to be mindful of expression level differences among tissue types, etc. 
- Workflow: Sample collection (freeze/RNAlater), isolate RNA, quality assessment of RNA (gel or bioanalyzer or qubit), rRNA depletion (selecting for molecules with poly-A tail to enrich for mRNA), fragmentation, cDNA synthesis, adding adapters (amplification element, primary sequencing site, barcode for multiplexing), amplification using PCR, sequence on platform of choice



##### Zoe: GBS/RADseq

- Use restriction sites to fragment DNA 
- Ligate adapters to each of your fragments with a barcode
- Workflow: Extract genomic DNA from your samples, digest with a restriction enzyme, ligate adapters, multiplex individuals, clean up fragments, PCR, check fragment size, send for sequencing
- Limitations: fragment bias for what gets amplified



##### Ben: Bisulfite/ATAC seq

- Bisulfite: used to identify methylated cytosine, which typically occurs in CG islands, typical of non-coding DNA or in promotors upstream of genes that aren't constantly expressed. 
  - Workflow: Isolate DNA, treat with sodium bisulfite (converts meytholated Cs into Us), PCR, Sequence samples and compare treated vs untreated samples (these CG islands will differ in their sequence) so this allows you to identify methylated vs non-methylated regions of the genome
- CHIPseq: acts at the level of histone modification, chromatin immunoprecipitation
  - Workflow: introduce a fixative to the DNA, fragment the DNA, introduce an antibody that is specific to your protein of interest which allows your targeted fragments to be precipitated out, decouple sequence and protein, and then you sequence
- ATACseq: looks at chromatin state
  - Workflow: introduce transposons that fragment open chromatin, transposons add adapters to fragments, sequence fragments
- HiC seq: identifies all regions where the DNA strand is interacting with itself and sequences them 

------
<div id='id-section4'/>   

### Entry 4: 2020-01-16, Thursday.   



------
<div id='id-section5'/>   

### Entry 5: 2020-01-17, Friday.   



------
<div id='id-section6'/>   

### Entry 6: 2020-01-20, Monday.   



------
<div id='id-section7'/>   

### Entry 7: 2020-01-21, Tuesday.   



------
<div id='id-section8'/>   

### Entry 8: 2020-01-22, Wednesday.   

##### Jorge: Amplicon Seq

**Uses**: 
- Genome targeting
- Detection of hot-spots of mutation
- Gene fusion
- SNPs
- Metagenomics

**Workflow**: 
1. Sample selection
2. DNA or RNA extraction 
3. Select amplicon that you will sequence: ITS, CO1, 16S
4. Library prep
  - PCR using primers to focus on amplicon of choice
  - Optional purification step
  - 2nd PCR to attach barcode 
  - Size selection purification to isolate your amplicon
  - Pool samples
5. Sequence 
6. Bioinformatic procedure
  - Quality contreol
  - trimming
  - demultiplex
  - generate your OTUs (operational taxonomic unit)

##### Alison: Exon capture sequencing

 **Exon**: protein coding region of the gene
 **Exome**: portion of the genome that codes for genes
  - Prevalent in biomedical field and in evolutionary biology
  - More targeted approach than WGS
**Biomedical uses**: 
- disease causing variants are more likely to be found in the exome
- especially interested for rare diseases

**EcoEvo Uses**: 
- Genetic mapping of phenotypic traits
- Detect selection (particularly helpful for non-model organisms)
- Used in phylogenetic reconstruction
- Can also be used to analyze ancient DNA

**Workflow**: 
1. Sample collection & extraction
2. Fragmentation of DNA
3. Enriching library using probes
 - PCR: need to have primers designed
 - Denovo: create new probes, need some knowledge of transcriptome/RADseq/WGS
 - Divergent annotated genome: probes based on relatively close relative, requires annotate genomes
5. DNA purification
6. Quality control

------
<div id='id-section9'/>   

### Entry 9: 2020-01-23, Thursday.   



------
<div id='id-section10'/>   

### Entry 10: 2020-01-24, Friday.   



------
<div id='id-section11'/>   

### Entry 11: 2020-01-27, Monday.   

#####Steve lecture on population genomics

- Missed the first part of lecture
- With positive selection we expect to see a decrease in nucleotide diversity at the selected site. 
- The linkage measured between sites will increase, particularly with sites close to the site under selection
- The signature of this in the population looks similar to the signature of population expansion
  - Happening locally, not globally across the genome
- 




------
<div id='id-section12'/>   

### Entry 12: 2020-01-28, Tuesday.   



------
<div id='id-section13'/>   

### Entry 13: 2020-01-29, Wednesday.   

PopGen Coding Day One

##### Red spruce 

- Northen high elevation
- Southern populations form sky islands
  - Isolated and vulnerable
- Are there particular alleles in the fragmented populations that need to be preserved, since they are likely to go locally extinct
- People care about spruce restoration, and have planted out thousands of spruce trees
  - These restoration efforts aren't genetically informed
  - Can we maximize evolutionary potential and look for populations that are most climate adapted based on our analyses of which region of the genome correspond to adaptation to climate change
  - These results will translate directly to restoration efforts


##### Pipeline

1. Visualize the quality of the data using FastQC
2. Trim your data using Trimmomatic
3. Not a bad idea to visualize the post trimming results
4. Map reads to reference genome (our reference in this case is white spruce) using BWA
5. Use samtools and sambamba to do some post processing of the data. This converts alignment to binary form sam -> bam. Look for PCR duplicates. 

**So first we are going to navigate to our fastq files**

cd /data/project_data/RS_ExomeSeq/fastq/edge_fastq

**To look at the file and access the file inside**
**This shows us the first four lines**

zcat AB_05_R1_fastq.gz | head -n 4

**Header tells you info about the sequence. Then your sequence. Then an ascii representation of the quality of your sequence ... base by base. You can use these symbols to get your phred/q scores. This is a measure of how confident that there was a correct read of that base. What is loaded on the flow cell isn't necessarily the correct base though.** 

**Fastqc assignment:** 
- AB Steve
- BFA Thomas
- BRB Kate
- CR
- CRA Erika
- DG Zoe
- GFM Bertrand
- HR
- KOS Sandra
- MRC Ben
- MT
- PRK Brendan
- RP
- WA Jorge
- XCS Chege
- XCV Csenge
- XDS Lily
- XFS Kerry
- XGL Anoob
- XPK Shervin
- XSK Baxter
- XWS Alison

**Then relocate to your github directory on the terminal**
cd ~/<repo name>/myresults

**Then to make a new directory**

vim
I
```bash
#!/bin/bash
cd ~/<repo name>/myresults #navigate to the directory where you want to make a new directory
mkdir fastqc #make directory
for file in /data/project_data/RS_ExomeSeq/fastq/edge_fastq/AB*fastq.gz 
do
fastqc ${file} -o fastqc/ #direct output to fastqc file 
done
``` 
esc
shift:wq fastqc.sh (writes the file gives it a name and then quits the file)
enter
ll

**If you put the file in the wrong place*
mv filename dir/

**to change permissions**
chmod u+x file name

**This adds the permission to execute changes to a given file. Now you're ready to run the script** 

bash fastqc.sh

**Run fastqc on clean paired reads**
















------
<div id='id-section14'/>   

### Entry 14: 2020-01-30, Thursday.   



------
<div id='id-section15'/>   

### Entry 15: 2020-01-31, Friday.   



------
<div id='id-section16'/>   

### Entry 16: 2020-02-03, Monday.   

####Info Update from Kerry

**Effective population size**: The size of an ideal population (under HWE) according to population level stats about that population

- There are many reasons that the effective population size is different than the actual population size
  - Non-random mating
  - Selection
  - Uneven sex ratio
  - Reproductive skew
  - Changes in pop size
- Can estimate Ne in many ways ... by looking at...
  - nucleotide diversity
  - sex ratio
**Fst**: can be used as an estimation of population structure. Looking at differences between populations... when populations are more different, Fst is higher






------
<div id='id-section17'/>   

### Entry 17: 2020-02-04, Tuesday.   



------
<div id='id-section18'/>   

### Entry 18: 2020-02-05, Wednesday.   

####Popgen Day Two

1. **Can use wget function to download reference genome from internet**
2. **Not mapping to the entire reference, just pulling out contigs that one or more of our probes are in**

3. **Once we reduce our reference, we look at N50: size of contig that contains 50% of genome after sorting genome by contig size. This gives us an idea of quality of our data, especially in the context of assembly** 

Writing bash script below .... saved as mypipeline.sh and save it in myscripts directory ... this is going to serve as our wrapper script

```bash
#!/bin/bash

#We'll use this as a wrapper to run our different mapping scripts

#define variable myrepo with path to repo on the server

myrepo=""

# My population:

mypop=""

#Directory to our cleaned and paired reads:

input ="/data/project_data/RS_ExomeSeq/fastq/edge_fastq/pairedcleanreads/${mypop}" #Each student will add their own pop to the end of this path

#Directory to store the outputs of our mapping

output="/data/project_data/RS_ExomeSeq/mapping"

#Run mapping.sh

source ./mapping.sh

#Run the post processing steps

source ./process_bam.sh

```

To check to make sure this works we can copy and paste into terminal and then use the echo command and it should spit the variable back to us in curly brackets

Now create a new bash script mapping.sh in the myscripts folder

```bash
#!bin/bash

#This script will run the read mapping using bwa

#create a variable that points to the reduced reference genome that we made earlier

ref="data/project_data/RS_ExomeSeq/ReferenceGenomes/Pabies1.0-genome_reduced.fa"

#Write a loop to map each individual within my population

for forward in $input*_R1.cl.pd.fq #initializes the forward read
do
  reverse=${forward/_R1.cl.pd.fq/_R2.cl.pd.fq} #defining reverse by swapping out extension
  f=${forward/_R1.cl.pd.fq/} #this will give you everything without the extension
  name=`basename ${f}` #using backtick for running bash command
  bwa mem -t 1 -M ${ref} ${forward} ${reverse} > ${output}/BWA/${name}.sam
done
```

We will be running bwa ... can type in program name in ternimal to get info on it

Okayyyy... so new script process_bam.sh

```bash
#!/bin/bash
# This is where we will convert sam files to bam files. Then we will sort the bam files, remove PCR duplicates, and index them.

#First lets convert sam to bam; then we sort

for f in ${output}/BWA/${mypop}*sam
do 
  out=${f/.sam/}
  sambamba-0.7.1-linus-static view -S --format=bam ${f} -o ${out}.bam
  samtools sort ${out}.bam -o ${out}.sorted.bam
done

#Now let's remove the PCR dupes

for file in ${output}/BWA/${mypop}*.sorted.bam
do
  f=${file/.sorted.bam/}
  sambamba-0.7.1-linus-static markdup -r -t 1 ${file} ${f}.sorted.rmdup.bam
done

#Now to finish, we'll index our files 

for file in ${output}/BWA/${mypop}*.sorted.rmdup.bam

do
  samtools index ${file}
done
```


  

------
<div id='id-section19'/>   

### Entry 19: 2020-02-06, Thursday.   



------
<div id='id-section20'/>   

### Entry 20: 2020-02-07, Friday.   



------
<div id='id-section21'/>   

### Entry 21: 2020-02-10, Monday.   



------
<div id='id-section22'/>   

### Entry 22: 2020-02-11, Tuesday.   



------
<div id='id-section23'/>   

### Entry 23: 2020-02-12, Wednesday.   

By now folks should have their SAM files for their pops in 

/data/project_data/RS_ExomeSeq/mapping/BWA/


Look at the SA file using head and tail

```bash
tail -n 100 FILENAME.sam
```
The SAM file contains lots of important info on the alignment of your sequence to the reference

Can use the command flagstat to get a summary for how our mapping went

```bash
samtools flagstat FILENAME.sam
```
Time to write a new bash script called bam_stats.sh This script will show us read counts and depth of coverage

```bash
samtools flagstat file.sorted.rmdup.bam | awk 'NR>=6&&NR<=13 {print $1}' | column -x
>> ${myrepo}/myresults/${mypop}.flagstats.txt
samtools depth file.sorted.rmdup.bam | awk '{sum+=$3} END {print sum/NR}
>> ${myrepo}/myresults/${mypop}.coverage.txt

Now while thats running can look at the alignment files using tview

```bash 
samtools tview /data/project_data/RS_ExomeSeq/mapping/BWA/AB_05.sorted.rmdup.bam /data/project_data/RS_ExomeSeq/ReferenceGenomes/Pabies1.0-genome_reduced.fa
```
Genotype free popgen using genotype likelihoods 
- Growing movement in popgen analysis of NGS data is embracing the use of genotype likelihoods to calculate stats based on each individual having a likelihood of being each genotype

- A genotype likelihood is the probablility of observing th sequence data given the genotype of the individual at that site
  - We're going to use this approach with the program ANGSD 
  - Can use this program and estimated genotype likelihoods to estimate SFS, nucleotide diversity, Fst, PCA
  
In your myscripts folder create a new file ANGSD_mypop.sh

```bash
myrepo="/users/s/r/srkeller/Ecological_Genomics/Spring_2020"

mkdir ${myrepo}/myresults/ANGSD

output="${myrepo}/myresults/ANGSD"

mypop="AB"

ls /data/project_data/RS_ExomeSeq/mapping/BWA/${mypop}_*sorted.rm*.bam >${output}/${mypop}_bam.list
```
Estimate your GLs and allele frquencies after filtering for depth, base and mapping quality

```bash
REF="/data/project_data/RS_ExomeSeq/ReferenceGenomes/Pabies1.0-genome_reduced.fa"

# Estimating GL's and allele frequencies for all sites with ANGSD

ANGSD -b ${output}/${mypop}_bam.list \
-ref ${REF} -anc ${REF} \
-out ${output}/${mypop}_allsites \
-nThreads 1 \
-remove_bads 1 \
-C 50 \
-baq 1 \
-minMapQ 20 \
-minQ 20 \
-setMinDepth 3 \
-minInd 2 \
-setMinDepthInd 1 \
-setMaxDepthInd 17 \
-skipTriallelic 1 \
-GL 1 \
-doCounts 1 \
-doMajorMinor 1 \
-doMaf 1 \
-doSaf 1 \
-doHWE 1 \
# -SNP_pval 1e-6

#Now lets calculate the SFS for the folded minor allele spectra

ANGSD -b ${output}/${mypop}_bam.list \
-ref ${REF} -anc ${REF} \
-out ${output}/${mypop}folded_allsites \
-nThreads 1 \
-remove_bads 1 \
-C 50 \
-baq 1 \
-minMapQ 20 \
-minQ 20 \
-setMinDepth 3 \
-minInd 2 \
-setMinDepthInd 1 \
-setMaxDepthInd 17 \
-skipTriallelic 1 \
-GL 1 \
-doCounts 1 \
-doMajorMinor 1 \
-doMaf 1 \
-doSaf 1 \
-fold 1 \

#Get a rough first estimate of the SFS, and then use as a prior for the next estimate

realSFS ${output}/${mypop}_folded_allsites.saf.idx -maxIter 1000 -tole 1e-6 -P 1 > ${output}/${mypop}_outFold.sfs

#Get a refined estimate of the SFS and doTheta

ANGSD -b ${output}/${mypop}_bam.list \
-ref ${REF} -anc ${REF} \
-out ${output}/${mypop}folded_allsites \
-nThreads 1 \
-remove_bads 1 \
-C 50 \
-baq 1 \
-minMapQ 20 \
-minQ 20 \
-setMinDepth 3 \
-minInd 2 \
-setMinDepthInd 1 \
-setMaxDepthInd 17 \
-skipTriallelic 1 \
-GL 1 \
-doCounts 1 \
-doMajorMinor 1 \
-doMaf 1 \
-doSaf 1 \
-fold 1 \
-pest ${output}/${mypop}_outFold.sfs \
-doThetas 1

#Use the doTheta output from above to etimate nucleotide diversity

thetaStat do_stat ${output}/${mypop}folded_allsites.thetas.idx

```

1. Estimate the rough SFS ... then we are going to estimate our SFS again using our previous SFS as a prior
2. doTheta - this will give us diversity stats
3. theta_stats - this gives us readable diversity stats
4. move to R environment to look at our results 

Okay so now we are in R and looking at our results

```{r}
setwd("~/path to files")

list.files()

SFS <- scan("ABoutFold.sfs"")

sumSFS <- sum(SFS)

pctPoly = 100*1-(SFS[1]/sumSFS)

plotSFS <- SFS[-c(l,length(SFS))]

barplot(plotSFS)

div <- read.table("AB_folded_allsites.thetas.idx.pestPG")

colnames(div) = c("window","chrname","wincenter","tW","tP","tF","tH","tL","tajD","fulif","fuliD","fayH","zengsE","numSites")

#Scale stats as persite estimates

div$tWpersite = div$tW/div$numSites
div$tPpersite = div$tW/div$numSites

pdf("AB_diversity_stats.pdf")
par(mfrow= c(2,2))

hist(div$tWpersite, col="gray", xlab="Theta-W", main="")

hist(div$tPpersite, col="gray", xlab="Theta-Pi", main="")

hist(div$tajD, col="gray", xlab="Tajima's D", main="")

barplot(plotSFS)

dev.off()

summary(div)

#positive shift of TajD indicating bottleneck

```



------
<div id='id-section24'/>   

### Entry 24: 2020-02-13, Thursday.   



------
<div id='id-section25'/>   

### Entry 25: 2020-02-14, Friday.   



------
<div id='id-section26'/>   

### Entry 26: 2020-02-17, Monday.   



------
<div id='id-section27'/>   

### Entry 27: 2020-02-18, Tuesday.   



------
<div id='id-section28'/>   

### Entry 28: 2020-02-19, Wednesday.   

Continuing notes in last week's class entry 23

------
<div id='id-section29'/>   

### Entry 29: 2020-02-20, Thursday.   



------
<div id='id-section30'/>   

### Entry 30: 2020-02-21, Friday.   



------
<div id='id-section31'/>   

### Entry 31: 2020-02-24, Monday.   


#### Transcriptomics Day One

- **Transcriptomics**: allows for you to experimentally control environmental conditions constant to reveal genetically controlled differences of phenotypes at the molecular level

- **Phenotypes**: Observable characteristics of an organism

- **Reverse Ecology**: Looking at influence of environment on transcription
- Genetic diversity at the DNA level can impact phenotype
  - Mutations in the coding region resulting in aa changes
  - Splice site variation
  - Regulatory regions could impact levels of expression and the onset of expression and tissue type where the gene is expressed
  - Post translational modifications 
  - epigenetic modifications
  
- **Why transcriptomics**?
  - Active picture of what is being expressed
  - Global/unbiased
  - Cheap
  - Don't need prior resources
  
- **Factors of consideration (Should be question driven)**: 
  - Common garden
  - Treatments/conditions
  - Populations
  - Tissue/cell
  - Life history stage
  - Transgenerational effects
  - Sex and reproductive stage
- **Workflow**: 
  1. Careful experimental design
  2. Experiment
  3. Tissue/individual/pool Sampling
  4. Extract and sequence RNA
  5. Process and analyze sequence data
  6. Integrate: GO enrichment, Network analyses, SNPs, diversity stats, microbiome, epigenetic data, proteomics, environmental data 

------
<div id='id-section32'/>   

### Entry 32: 2020-02-25, Tuesday.   



------
<div id='id-section33'/>   

### Entry 33: 2020-02-26, Wednesday.   

#### First Transcriptomics coding session

Pop assignments

ASC_C: Csenge
ASC_D: Csenge
ASC_H: Brendan

BRU_C: Brendan
BRU_D: Alison
BRU_H: Alison

CAM_C: Ben
CAM_D: Ben
CAM_H: Thomas

ESC_C: Thomas
ESC_D: Bertrand
ESC_H: Bertrand

JAY_C: Kate
JAY_D: Kate
JAY_H: Sandra

KAN_C: Sandra
KAN_D: Jorge
KAN_H: Jorge

LOL_C: Kerry
LOL_D: Kerry
LOL_H: Erika

MMF_C: Erika
MMF_D: Chege
MMF_H: Chege

NOR_C: Zoe
NOR_D: Zoe
NOR_H: Shervin

XBM_C: Shervin
XBM_D: Anoob
XBM_H: Anoob

Run FastQC on on populations

```bash

mkdir ~/<myrepo>/myresults/RNA_fastqc

for file in AB*fastq.gz

do

 fastqc ${file} -o ~/<myrepo>/myresults/RNA_fastqc

done
```

For issues with git push/pull 

```bash
vim .gitignore
myresults/ANGSD/*
```
```bash
git pull
git add -A
git commit -m ""
git push
```

This should allow you to ignore the big ANGSD files that are preventing people from updating their github

Next we want to run fastqc on the cleaned reads

```bash
cp OldFileName.sh NewFileName.sh
```

Then you can vim into that new file and update to run fastqc on the cleaned reads

```bash

mkdir ~/<myrepo>/myresults/RNA_fastqcClean

for file in AB*fastq.gz

do

 fastqc ${file} -o ~/<myrepo>/myresults/RNA_fastqcClean

done
```

------
<div id='id-section34'/>   

### Entry 34: 2020-02-27, Thursday.   



------
<div id='id-section35'/>   

### Entry 35: 2020-02-28, Friday.   



------
<div id='id-section36'/>   

### Entry 36: 2020-03-02, Monday.   

#### Differential Gene Expression info update

##### What is DGE?
- Differences in transcript abundance between groups
- Tracking how expression in specific genes are changing 

##### Normalization
- So you have your counts data matrix 
 - Genes in each row, samples in each column, counts in each cell
- Normalization addresses two different problems
  - Depth 
  - Library composition (differential read depth from gene to gene)
- Normalization procedures
  - Counts per million
   - only accounts for sequencing depth
  - Transcripts/fragments per kb million
   - Account for depth and gene length 
    - longer genes will disproportionately map successfully
  - EdgeR
   - accounts for depth, gene size, and library composition
  - DESeq2
   - accounts for depth and composition 

##### Differential expression
- We need to account for multiple testing 
 - One way to manage that is by decreasing the number of tests that you are doing
  - DESeq does this with independent filtering by some sort of cut-off
 - Correction for multiple tests (adjusted p-value) to control number of false positives
- DESeq2 uses GLM and negative binomial distribution and wald test to determine differences in counts between "genes"

##### Visualization
- Sequencing summary statistics
- PCA to look at the differential expression at the level of the transcriptome
- Heat maps
- Venn diagrams
- Volcano plots
- MA plots
- LFC scatter plot
 - shared things along the 1/1 line
- Individual gene treatment response curves

##### Enrichment analyses
- Comparing differentially expressed genes to gene sets (GO, KEGG, etc)
- Over representation analysis: you are looking at whether or not differential expression is concentrated in certain functional areas of the genome more so than they would by chance
- Rank based method (log fold change)
 - Are genes within a set clustered towards one end or another of the rank list 























------
<div id='id-section37'/>   

### Entry 37: 2020-03-03, Tuesday.   



------
<div id='id-section38'/>   

### Entry 38: 2020-03-04, Wednesday.   

The first step is to index into the transcriptome (Melissa already did this)

```bash
cd /data/project_data/RS_RNAseq/ReferenceTrancriptome/
salmon index -t Pabies1.0-all-cds.fna.gz -i Pabies_cds_index --decoys decoys.txt -k 31
```

Next step is to run quantification with Salmon

The first thing we need to do is write a bash script to run the quantification

```bash
!/bin/bash

cd/data/project_data/RS_RNASeq/fastq/cleanreads

for file in ESC_01_D*.R1.cl.fq

do salmon quant -i /data/project_data/RS_RNASeq/ReferenceTranscriptome/Pabies_HC27_index -l A -r /data/project_data/RS_RNASeq/fastq/cleanreads/${file} --validateMappings -o /data/project_data/RS_RNASeq/salmon/cleanedreads/${file}
done
```
Now we want to look at our mapping rates... look at this within the cleanreads directory

```bash
grep -r --include \*.log -e 'Mapping rate'
```
Not getting great mapping... so going to try a different index

```bash
!/bin/bash

cd/data/project_data/RS_RNASeq/fastq/cleanreads

for file in ESC_01_D*.R1.cl.fq

do salmon quant -i /data/project_data/RS_RNASeq/ReferenceTranscriptome/Pabies_cds_index -l A -r /data/project_data/RS_RNASeq/fastq/cleanreads/${file} --validateMappings -p 1 --seqBias -o /data/project_data/RS_RNASeq/salmon/HCmapping/${file}
done
```

Melissa ran code below in class to grab quant.sf files

```r
library(tximportData)
library(tximport)

#locate the directory containing the files. 
dir <- "/data/project_data/RS_RNASeq/salmon/"
list.files(dir)

# read in table with sample ids
samples <- read.table("/data/project_data/RS_RNASeq/salmon/RS_samples.txt", header=TRUE)

# now point to quant files
all_files <- file.path(dir, samples$sample, "quant.sf")
names(all_files) <- samples$sample

# what would be used if linked transcripts to genes
#txi <- tximport(files, type = "salmon", tx2gene = tx2gene)
# to be able to run without tx2gene
txi <- tximport(all_files, type = "salmon", txOut=TRUE)  
names(txi)

head(txi$counts)

countsMatrix <- txi$counts
dim(countsMatrix)
#[1] 66069    76

# To write out
write.table(countsMatrix, file = "RS_countsMatrix.txt", col.names = T, row.names = T, quote = F) 
```


------
<div id='id-section39'/>   

### Entry 39: 2020-03-05, Thursday.   



------
<div id='id-section40'/>   

### Entry 40: 2020-03-06, Friday.   



------
<div id='id-section41'/>   

### Entry 41: 2020-03-09, Monday.   



------
<div id='id-section42'/>   

### Entry 42: 2020-03-10, Tuesday.   



------
<div id='id-section43'/>   

### Entry 43: 2020-03-11, Wednesday.   



------
<div id='id-section44'/>   

### Entry 44: 2020-03-12, Thursday.   



------
<div id='id-section45'/>   

### Entry 45: 2020-03-13, Friday.   



------
<div id='id-section46'/>   

### Entry 46: 2020-03-16, Monday.   



------
<div id='id-section47'/>   

### Entry 47: 2020-03-17, Tuesday.   



------
<div id='id-section48'/>   

### Entry 48: 2020-03-18, Wednesday.   

#### Transcriptomics Day Three

[Link to Rmd file](TranscriptomicsRRRRdAYtHREE.html)


------
<div id='id-section49'/>   

### Entry 49: 2020-03-19, Thursday.   



------
<div id='id-section50'/>   

### Entry 50: 2020-03-20, Friday.   



------
<div id='id-section51'/>   

### Entry 51: 2020-03-23, Monday.   



------
<div id='id-section52'/>   

### Entry 52: 2020-03-24, Tuesday.   



------
<div id='id-section53'/>   

### Entry 53: 2020-03-25, Wednesday.   



------
<div id='id-section54'/>   

### Entry 54: 2020-03-26, Thursday.   



------
<div id='id-section55'/>   

### Entry 55: 2020-03-27, Friday.   



------
<div id='id-section56'/>   

### Entry 56: 2020-03-30, Monday.   



------
<div id='id-section57'/>   

### Entry 57: 2020-03-31, Tuesday.   



------
<div id='id-section58'/>   

### Entry 58: 2020-04-01, Wednesday.   



------
<div id='id-section59'/>   

### Entry 59: 2020-04-02, Thursday.   



------
<div id='id-section60'/>   

### Entry 60: 2020-04-03, Friday.   



------
<div id='id-section61'/>   

### Entry 61: 2020-04-06, Monday.   



------
<div id='id-section62'/>   

### Entry 62: 2020-04-07, Tuesday.   



------
<div id='id-section63'/>   

### Entry 63: 2020-04-08, Wednesday.   



------
<div id='id-section64'/>   

### Entry 64: 2020-04-09, Thursday.   



------
<div id='id-section65'/>   

### Entry 65: 2020-04-10, Friday.   



------
<div id='id-section66'/>   

### Entry 66: 2020-04-13, Monday.   



------
<div id='id-section67'/>   

### Entry 67: 2020-04-14, Tuesday.   



------
<div id='id-section68'/>   

### Entry 68: 2020-04-15, Wednesday.   



------
<div id='id-section69'/>   

### Entry 69: 2020-04-16, Thursday.   



------
<div id='id-section70'/>   

### Entry 70: 2020-04-17, Friday.   



------
<div id='id-section71'/>   

### Entry 71: 2020-04-20, Monday.   



------
<div id='id-section72'/>   

### Entry 72: 2020-04-21, Tuesday.   



------
<div id='id-section73'/>   

### Entry 73: 2020-04-22, Wednesday.   



------
<div id='id-section74'/>   

### Entry 74: 2020-04-23, Thursday.   



------
<div id='id-section75'/>   

### Entry 75: 2020-04-24, Friday.   



------
<div id='id-section76'/>   

### Entry 76: 2020-04-27, Monday.   



------
<div id='id-section77'/>   

### Entry 77: 2020-04-28, Tuesday.   



------
<div id='id-section78'/>   

### Entry 78: 2020-04-29, Wednesday.   



------
<div id='id-section79'/>   

### Entry 79: 2020-04-30, Thursday.   



------
<div id='id-section80'/>   

### Entry 80: 2020-05-01, Friday.   



------
<div id='id-section81'/>   

### Entry 81: 2020-05-04, Monday.   



------
<div id='id-section82'/>   

### Entry 82: 2020-05-05, Tuesday.   



------
<div id='id-section83'/>   

### Entry 83: 2020-05-06, Wednesday.   



------
<div id='id-section84'/>   

### Entry 84: 2020-05-07, Thursday.   



------
<div id='id-section85'/>   

### Entry 85: 2020-05-08, Friday.   